

<!doctype html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>allinone.trainer package &#8212; SSL-toolkit 1.0.0 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="allinone.model package" href="allinone.model.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!--[if lt IE 9]>
    <script src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="allinone.model.html" title="allinone.model package"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SSL-toolkit 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="allinone.html" accesskey="U">allinone package</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">allinone.trainer package</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="allinone-trainer-package">
<h1>allinone.trainer package<a class="headerlink" href="#allinone-trainer-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-allinone.trainer.AdversariallyLearnedInference">
<span id="allinone-trainer-adversariallylearnedinference-module"></span><h2>allinone.trainer.AdversariallyLearnedInference module<a class="headerlink" href="#module-allinone.trainer.AdversariallyLearnedInference" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference">
<em class="property">class </em><code class="sig-name descname">AdversariallyLearnedInference</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_dict</span><span class="p">:</span> <span class="n">torch.nn.modules.container.ModuleDict</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">consistency_weight</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced trainer based on <a class="reference external" href="https://arxiv.org/pdf/1606.00704">Adversarially Learned Inference</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dict</strong> – The <code class="docutils literal notranslate"><span class="pre">generator_x</span></code>, <code class="docutils literal notranslate"><span class="pre">generator_z</span></code>, <code class="docutils literal notranslate"><span class="pre">discriminator_x</span></code>, <code class="docutils literal notranslate"><span class="pre">discriminator_z</span></code>, and <code class="docutils literal notranslate"><span class="pre">discriminator_x_z</span></code> model of trainer.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
<li><p><strong>consistency_weight</strong> – The consistency schedule of trainer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor, ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>preprocess data and return (TensorTuple, batch_size)</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.set_optimizer">
<code class="sig-name descname">set_optimizer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set optimizer(s) for model(s). You can override as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">YourTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.supervised_iteration">
<code class="sig-name descname">supervised_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.supervised_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.test_iteration">
<code class="sig-name descname">test_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.test_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.train_iteration">
<code class="sig-name descname">train_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.train_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.unsupervised_iteration">
<code class="sig-name descname">unsupervised_iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.AdversariallyLearnedInference.AdversariallyLearnedInference.unsupervised_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-allinone.trainer.InterpolationConsistency">
<span id="allinone-trainer-interpolationconsistency-module"></span><h2>allinone.trainer.InterpolationConsistency module<a class="headerlink" href="#module-allinone.trainer.InterpolationConsistency" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="allinone.trainer.InterpolationConsistency.InterpolationConsistency">
<em class="property">class </em><code class="sig-name descname">InterpolationConsistency</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">consistency_weight</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.InterpolationConsistency.InterpolationConsistency" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced trainer based on <a class="reference external" href="https://arxiv.org/abs/1903.03825">Interpolation Consistency Training for Semi-Supervised Learning</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The backbone model of trainer.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
<li><p><strong>consistency_weight</strong> – The consistency schedule of trainer. Corresponding to <span class="math notranslate nohighlight">\(w(t)\)</span> in the original paper.</p></li>
<li><p><strong>alpha</strong> – The EMA schedule of trainer. Corresponding to <span class="math notranslate nohighlight">\(\alpha\)</span> in the original paper.</p></li>
<li><p><strong>beta</strong> – The hyperparameter of beta function. Corresponding to <span class="math notranslate nohighlight">\(\alpha\)</span> in the original paper.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.InterpolationConsistency.InterpolationConsistency.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor, ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.InterpolationConsistency.InterpolationConsistency.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>preprocess data and return (TensorTuple, batch_size)</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.InterpolationConsistency.InterpolationConsistency.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.InterpolationConsistency.InterpolationConsistency.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.InterpolationConsistency.InterpolationConsistency.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.InterpolationConsistency.InterpolationConsistency.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.InterpolationConsistency.InterpolationConsistency.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.InterpolationConsistency.InterpolationConsistency.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-allinone.trainer.Ladder">
<span id="allinone-trainer-ladder-module"></span><h2>allinone.trainer.Ladder module<a class="headerlink" href="#module-allinone.trainer.Ladder" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="allinone.trainer.Ladder.Ladder">
<em class="property">class </em><code class="sig-name descname">Ladder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">lam_list</span><span class="p">:</span> <span class="n">List<span class="p">[</span>float<span class="p">]</span></span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.Ladder.Ladder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced trainer based on <a class="reference external" href="https://arxiv.org/abs/1507.02672">Semi-Supervised Learning with Ladder Networks</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The backbone model of trainer.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
<li><p><strong>lam_list</strong> – The order list of regularization coefficient, which describes how important to recovery signals.  Corresponding to <span class="math notranslate nohighlight">\(\lambda^i\)</span> in the original paper.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.Ladder.Ladder.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[Tuple[torch.Tensor, ...], ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.Ladder.Ladder.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>preprocess data and return (TensorTuple, batch_size)</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.Ladder.Ladder.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span><span class="p">…</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.Ladder.Ladder.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.Ladder.Ladder.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.Ladder.Ladder.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.Ladder.Ladder.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.Ladder.Ladder.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<div class="figure align-default" id="id1">
<img alt="_images/Ladder-Mnist-100.png" src="_images/Ladder-Mnist-100.png" />
<p class="caption"><span class="caption-text">The result of training LeNet-5 by the Ladder algorithm with 100 labeled images on MNIST Dataset.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="module-allinone.trainer.MeanTeacher">
<span id="allinone-trainer-meanteacher-module"></span><h2>allinone.trainer.MeanTeacher module<a class="headerlink" href="#module-allinone.trainer.MeanTeacher" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head" colspan="3"><p>The result of training LeNet-5 by Mean Teacher(consistency_weight) with 100/500 labeled images on MNIST Dataset.</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mean Accuracy(Three Trials)</p></td>
<td><p>100</p></td>
<td><p>500</p></td>
</tr>
<tr class="row-odd"><td><p>Mean Teacher(10.0)</p></td>
<td><p>88.22(89.76 87.19 87.71)</p></td>
<td><p>97.31(97.19 97.25 97.48)</p></td>
</tr>
<tr class="row-even"><td><p>Mean Teacher(1.0)</p></td>
<td><p>91.11(91.57 91.89 89.86)</p></td>
<td><p>97.32(97.44 97.41 97.12)</p></td>
</tr>
<tr class="row-odd"><td><p>Mean Teacher(0.1)</p></td>
<td><p>90.33(89.13 90.90 90.97)</p></td>
<td><p>96.5(96.30 96.61 96.58)</p></td>
</tr>
<tr class="row-even"><td><p>Mean Teacher(0.01)</p></td>
<td><p>87.4(86.75 87.31 88.13)</p></td>
<td><p>95.21(95.44 94.88 95.32)</p></td>
</tr>
<tr class="row-odd"><td><p>Only EMA</p></td>
<td><p>83.2(84.74 80.34 84.53)</p></td>
<td><p>95.01(94.68 94.70 95.64)</p></td>
</tr>
<tr class="row-even"><td><p>LeNet-5(with BN)</p></td>
<td><p>80.87(78.07 81.45 83.08)</p></td>
<td><p>94.69(95.16 94.22 94.69)</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="allinone.trainer.MeanTeacher.MeanTeacher">
<em class="property">class </em><code class="sig-name descname">MeanTeacher</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">consistency_weight</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">dataset_type</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.MeanTeacher.MeanTeacher" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced trainer based on <a class="reference external" href="https://arxiv.org/abs/1703.01780">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The backbone model of trainer.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
<li><p><strong>consistency_weight</strong> – The consistency schedule of trainer. Corresponding to <code class="docutils literal notranslate"><span class="pre">consistency</span> <span class="pre">cost</span> <span class="pre">coefficient</span></code> in the original paper.</p></li>
<li><p><strong>alpha</strong> – The EMA schedule of trainer. Corresponding to <span class="math notranslate nohighlight">\(\alpha\)</span> in the original paper.</p></li>
<li><p><strong>dataset_type</strong> – The type of dataset. Choose <code class="docutils literal notranslate"><span class="pre">mix</span></code> or <code class="docutils literal notranslate"><span class="pre">split</span></code> corresponding to dataset type.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.MeanTeacher.MeanTeacher.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor, ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.MeanTeacher.MeanTeacher.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>The labeled data and unlabeled data are combined if they were split previously.</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MeanTeacher.MeanTeacher.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.MeanTeacher.MeanTeacher.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MeanTeacher.MeanTeacher.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.MeanTeacher.MeanTeacher.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MeanTeacher.MeanTeacher.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.MeanTeacher.MeanTeacher.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<div class="figure align-default" id="id2">
<img alt="_images/MeanTeacher-Mnist-100500.png" src="_images/MeanTeacher-Mnist-100500.png" />
<p class="caption"><span class="caption-text">The result of training LeNet-5 by the Mean Teacher with 100/500 labeled images on MNIST Dataset.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="module-allinone.trainer.MixMatch">
<span id="allinone-trainer-mixmatch-module"></span><h2>allinone.trainer.MixMatch module<a class="headerlink" href="#module-allinone.trainer.MixMatch" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="allinone.trainer.MixMatch.MixMatch">
<em class="property">class </em><code class="sig-name descname">MixMatch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">temperature</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">beta</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">consistency_weight</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="n">dataset_type</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced trainer based on <a class="reference external" href="https://arxiv.org/abs/1905.02249">MixMatch: A Holistic Approach to Semi-Supervised Learning</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The backbone model of trainer.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
<li><p><strong>temperature</strong> – The temperature of sharpen function. Corresponding to <code class="docutils literal notranslate"><span class="pre">T</span></code> in the original paper.</p></li>
<li><p><strong>beta</strong> – The hyperparameter of beta function. Corresponding to <span class="math notranslate nohighlight">\(\alpha\)</span> in the original paper.</p></li>
<li><p><strong>consistency_weight</strong> – The consistency schedule of trainer. Corresponding to <span class="math notranslate nohighlight">\(\lambda_\mathcal{u}\)</span> in the original paper.</p></li>
<li><p><strong>dataset_type</strong> – The type of dataset. Choose <code class="docutils literal notranslate"><span class="pre">mix</span></code> or <code class="docutils literal notranslate"><span class="pre">split</span></code> corresponding to dataset type.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.MixMatch.MixMatch.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor, ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>The labeled data and unlabeled data are combined if they were split previously.</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MixMatch.MixMatch.generate_mixmatch">
<code class="sig-name descname">generate_mixmatch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">label_data</span></em>, <em class="sig-param"><span class="n">label_target</span></em>, <em class="sig-param"><span class="n">augment_unlabel_list</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch.generate_mixmatch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MixMatch.MixMatch.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MixMatch.MixMatch.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.MixMatch.MixMatch.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.MixMatch.MixMatch.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-allinone.trainer.VariationalAutoEncoder">
<span id="allinone-trainer-variationalautoencoder-module"></span><h2>allinone.trainer.VariationalAutoEncoder module<a class="headerlink" href="#module-allinone.trainer.VariationalAutoEncoder" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder">
<em class="property">class </em><code class="sig-name descname">VariationalAutoEncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">vae_model</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch.optim.optimizer.Optimizer</span></em>, <em class="sig-param"><span class="n">loss_f</span><span class="p">:</span> <span class="n">Callable</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">reporters</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>homura.reporters._ReporterBase<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scheduler</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>torch.optim.lr_scheduler._LRScheduler<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verb</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_cudnn_benchmark</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">report_accuracy_topk</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></p>
<p>Reproduced Code based on <a class="reference external" href="https://arxiv.org/abs/1406.5298">Semi-Supervised Learning with Deep Generative Models</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_model</strong> – An inference model to classify.</p></li>
<li><p><strong>vae_model</strong> – An vae model to reconstruct images as an auxiliary task.</p></li>
<li><p><strong>optimizer</strong> – The optimizer of trainer.</p></li>
<li><p><strong>loss_f</strong> – The classfication loss of trainer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.data_preprocess">
<code class="sig-name descname">data_preprocess</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor, ...]) -&gt; (typing.Tuple[torch.Tensor, ...], &lt;class 'int'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.data_preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>The labeled data and unlabeled data are combined if they were split previously.</p>
</dd></dl>

<dl class="py method">
<dt id="allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>torch.Tensor<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Mapping<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="headerlink" href="#allinone.trainer.VariationalAutoEncoder.VariationalAutoEncoder.state_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-allinone.trainer.utils">
<span id="allinone-trainer-utils-module"></span><h2>allinone.trainer.utils module<a class="headerlink" href="#module-allinone.trainer.utils" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="allinone.trainer.utils.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em><span class="sig-paren">)</span><a class="headerlink" href="#allinone.trainer.utils.unroll" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-allinone.trainer">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-allinone.trainer" title="Permalink to this headline">¶</a></h2>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">allinone.trainer package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.AdversariallyLearnedInference">allinone.trainer.AdversariallyLearnedInference module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.InterpolationConsistency">allinone.trainer.InterpolationConsistency module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.Ladder">allinone.trainer.Ladder module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.MeanTeacher">allinone.trainer.MeanTeacher module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.MixMatch">allinone.trainer.MixMatch module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.VariationalAutoEncoder">allinone.trainer.VariationalAutoEncoder module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer.utils">allinone.trainer.utils module</a></li>
<li><a class="reference internal" href="#module-allinone.trainer">Module contents</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="allinone.model.html"
                        title="previous chapter">allinone.model package</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/allinone.trainer.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="allinone.model.html" title="allinone.model package"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">SSL-toolkit 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="allinone.html" >allinone package</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">allinone.trainer package</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, SMILElab.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.3.1.
    </div>
  </body>
</html>